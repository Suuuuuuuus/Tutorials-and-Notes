\documentclass[UTF8]{book}
%\usepackage{ctex}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{bm}
\usepackage{makeidx}
\usepackage{enumitem}
\usepackage{rotating} 
\usepackage{yhmath}
\usepackage{textcomp,booktabs}
\usepackage[usenames,dvipsnames]{color}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{gensymb}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{pifont}
\usepackage[all,pdf]{xy}
\usepackage{exscale}
\usepackage{blindtext}
\usepackage{hyperref}
\hypersetup{
colorlinks=true,
linkcolor=black
}
\usepackage{nameref}
\usepackage{relsize}
\usepackage{titlesec}
\usepackage{ifthen}
\usepackage{array}
\usepackage[flushleft]{threeparttable}
\usepackage{diagbox}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{ulem}
\usepackage{xcolor}
\usepackage{color}
\usepackage{mathptmx}
\usepackage{amssymb}
\usepackage{geometry}
\geometry{a4paper, left=2.54cm,right=2.54cm,top=2.54cm,bottom=2.54cm}
%\geometry{b5paper, left=1.6cm,right=2cm,top=2cm,bottom=2cm}
\usepackage{mathrsfs}
\usepackage{tikz,tkz-euclide}
\usepackage{tikz}
\usetikzlibrary{patterns}
\usetikzlibrary{shapes,arrows}
\usepackage{esvect}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{} % clear all fields 
\cfoot{}
\fancyhead[LE,RO]{\thepage} 
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\linespread{1.4}
\date{}
\graphicspath{ {Graphs} }
\usepackage{listings}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  backgroundcolor=\color{gray!20!white}
}
\definecolor{codegray}{gray}{0.8}
\newcommand{\code}[1]{\colorbox{codegray}{\texttt{#1}}}
%通用：
\newcounter{mylabelcounter}
\makeatletter
\newcommand{\labeltext}[2]{%
#1\refstepcounter{mylabelcounter}%
\immediate\write\@auxout{%
  \string\newlabel{#2}{{1}{\thepage}{{\unexpanded{#1}}}{mylabelcounter.\number\value{mylabelcounter}}{}}%
}%
}
%Xsum
\DeclareFontFamily{U} {cmex}{}
\DeclareFontShape{U}{cmex}{m}{n}{
  <-6> cmex5
  <6-7> cmex6
  <7-8> cmex7
  <8-9> cmex8
  <9-10> cmex9
  <10-12> cmex10
  <12-> cmex12}{}
\DeclareSymbolFont{Xcmex} {U} {cmex}{m}{n}
\DeclareMathSymbol{\Xdsum}{\mathop}{Xcmex}{88}
\DeclareMathSymbol{\Xtsum}{\mathop}{Xcmex}{80}
\DeclareMathOperator*{\Xsum}{\mathchoice{\Xdsum}{\Xtsum}{\Xtsum}{\Xtsum}}
%Xsum
%choice
\newcommand{\fourch}[4]{%~\hfill(\qquad)\\
\begin{tabular}{*{4}{@{}p{0.25\textwidth}}}(A)~#1 & (B)~#2 & (C)~#3 & (D)~#4\end{tabular}}
\newcommand{\twoch}[4]{%~\hfill(\qquad)\\
\begin{tabular}{*{2}{@{}p{0.5\textwidth}}}(A)~#1 & (B)~#2\end{tabular}\\\begin{tabular}{*{2}{@{}p{0.5\textwidth}}}(C)~#3 & (D)~#4\end{tabular}}
\newcommand{\onech}[4]{%~\hfill(\qquad)\\
(A)~#1 \\ (B)~#2 \\ (C)~#3 \\ (D)~#4}
 
\newlength\widthcha
\newlength\widthchb
\newlength\widthchc
\newlength\widthchd
\newlength\widthch
\newlength\tabmaxwidth
\setlength\tabmaxwidth{1\textwidth}
\newlength\fourthtabwidth
\setlength\fourthtabwidth{0.25\textwidth}
\newlength\halftabwidth
\setlength\halftabwidth{0.5\textwidth}
\newcommand{\choice}[4]{\settowidth\widthcha{AM.#1}\setlength{\widthch}{\widthcha}
    \settowidth\widthchb{BM.#2}
    \ifthenelse{\widthch<\widthchb}{\setlength{\widthch}{\widthchb}}{}
    \settowidth\widthchb{CM.#3}
    \ifthenelse{\widthch<\widthchb}{\setlength{\widthch}{\widthchb}}{}
    \settowidth\widthchb{DM.#4}
    \ifthenelse{\widthch<\widthchb}{\setlength{\widthch}{\widthchb}}{}
    \ifthenelse{\widthch<\fourthtabwidth}{\fourch{#1}{#2}{#3}{#4}}
    {\ifthenelse{\widthch<\halftabwidth\and\widthch>\fourthtabwidth}{\twoch{#1}{#2}{#3}{#4}}
        {\onech{#1}{#2}{#3}{#4}}}}
%choice
% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
morekeywords={self},              % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=single,                         % Any extra options here
showstringspaces=false
}}


% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}
%%%%%
% Bash style for highlighting
\newcommand\bashstyle{\lstset{
language=bash,
basicstyle=\ttm\normalsize,
tabsize=4,
morekeywords={self, head, tail, uniq, sort, grep, cat, cut, echo, wc, cp, rm, mkdir, cd, nano, man, ls, history, bash, rmdir, find, plink, bcftools, bedtools, octopus},              % Add keywords here
keywordstyle=\color{deepblue}\normalsize\bfseries,
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=single,                         % Any extra options here
showstringspaces=false
}}


% Python environment
\lstnewenvironment{bash}[1][]
{
\bashstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\bashexternal[2][]{{
\bashstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\bashinline[1]{{\bashstyle\lstinline!#1!}}
%%%%%
\newcommand{\dollar}{\mbox{\textdollar}}
\newcommand{\dps}[1]{\ensuremath{\displaystyle{#1}}}
\newcommand\ffrac[2]{\ensuremath{\dfrac{\;#1\;}{\;#2\;}}}
\newcommand{\comma}{\, \; \;\mathclap{\text{，}}} %用于mathmode中的逗号
\newcommand{\semicolon}{\, \; \;\mathclap{\text{；}}} %用于mathmode中的分号
\newcommand{\pl}{\phantom{l}} %用来占位
\newcommand{\un}{\ding{172}}
\newcommand{\deux}{\ding{173}}
\newcommand{\trois}{\ding{174}}
\newcommand{\quatre}{\ding{175}}
\newcommand{\et}{&}
\newcommand{\f}{^2}
\newcommand{\xz}{(\qquad)}
\newcommand{\tk}{\underline{\qquad\qquad}}
%高等数学：
\renewcommand{\d}{\,\mathrm{d}}
\newcommand{\dt}{\,\mathrm{d}t}
\newcommand{\dr}{\,\mathrm{d}r}
\newcommand{\du}{\,\mathrm{d}u}
\newcommand{\dv}{\,\mathrm{d}v}
\newcommand{\dx}{\,\mathrm{d}x}
\newcommand{\dy}{\,\mathrm{d}y}
\newcommand{\dz}{\,\mathrm{d}z}
\newcommand{\df}{\,\mathrm{d}f}
\newcommand{\bigmid}{\, \bigg | \,} %用于集合中有分数的情况
\newcommand\matharr{\tikz[baseline=-0.4ex]\draw[-stealth] (0,0) -- + (3mm,0);} %用于下标中的右箭头
\newcommand\textarr{\; \tikz[baseline=-0.55ex]\draw[-stealth] (0,0) -- + (4mm,0);} %用于文本中的右箭头，注意用占位符调整前后间距
\newcommand{\limite}[2]{\ensuremath{\lim\limits_{#1\matharr #2}}} %#1趋向于#2
\newcommand{\dlimite}[4]{\ensuremath{\displaystyle{\lim_{\substack{ \phantom{l}#1\matharr #2\phantom{l} \\ #3\matharr #4}}}}} %#重极限：1趋向于#2，#3趋向于#4，phantom{l}用来占位
\newcommand{\neighbr}{\ensuremath{\mathring{U}(x_0\comma \delta)}} %去心邻域U
\newcommand{\neighbor}{\ensuremath{U(x_0\comma \delta)}} %邻域U
\newcommand{\tikzrm}[1]{
	\fill[white] #1 circle(1.5pt);
	\draw #1 circle(1.5pt);
}
\newcommand{\derivee}[4]{
	\ffrac{\,\mathrm{d}^{#1}#2}{\,\mathrm{d}#3^{#4}}
}
\newcommand{\intscript}[2]{\biggl.\biggr|_{\, #2}^{\, #1}} %求出原函数以后代入的积分上下限
\newcommand{\concept}[1]{\textcolor{magenta}{#1}}
\newcommand{\highlight}[1]{\textcolor{red}{#1}}
\renewcommand{\emph}[1]{\textcolor{blue}{#1}}
\newcommand{\dint}[2]{\ensuremath{\displaystyle{\int_{#2}^{#1}}}}
\newcommand{\diint}[4]{\ensuremath{\displaystyle{\int_{#2}^{#1}\int_{#4}^{#3}}}}
\newcommand{\bint}{\mathlarger{\int}} %用于将幂次上的积分号放大
\newcommand{\exiint}{\ensuremath{\!\!\!}} %用于缩短累次积分中积分号的距离
\newcommand{\fxy}{\ensuremath{f(x\comma y)}}
\newcommand{\xoyo}{\ensuremath{(x_0\comma y_0)}}
\newcommand{\series}{\ensuremath{\dps{\Xsum_{n=1}^\infty}}} %级数
\newcommand{\serieso}{\ensuremath{\dps{\Xsum_{n=0}^\infty}}} %0开始的级数
%线性代数：
\newcommand{\pA}{\ensuremath{\pmb{A}}}
\newcommand{\pB}{\ensuremath{\pmb{B}}}
\newcommand{\pC}{\ensuremath{\pmb{C}}}
\newcommand{\pO}{\ensuremath{\pmb{O}}}
\newcommand{\pP}{\ensuremath{\pmb{P}}}
\newcommand{\pQ}{\ensuremath{\pmb{Q}}}
\newcommand{\pE}{\ensuremath{\pmb{E}}}
\newcommand{\px}{\ensuremath{\pmb{x}}}
\newcommand{\pX}{\ensuremath{\pmb{X}}}
\newcommand{\pR}{\ensuremath{\pmb{R}}}
\newcommand{\pZ}{\ensuremath{\pmb{Z}}}
\newcommand{\pal}{\ensuremath{\pmb{\alpha}}}
\newcommand{\pbe}{\ensuremath{\pmb{\beta}}}
\newcommand{\pxi}{\ensuremath{\pmb{\xi}}}
\newcommand{\pet}{\ensuremath{\pmb{\eta}}}
\renewcommand{\t}{\ensuremath{^\mathrm{T}}}
\newcommand\laarr{\qquad\tikz\draw[-stealth] (0,0) -- + (7mm,0);\qquad} %用于矩阵中的初等变换
\newcommand{\laarrt}[1]{\qquad\tikz\draw[-stealth] (0,0) -- (4mm,0) node[above]{#1}--+ (4mm,0);\qquad} %初等变换上带字
%概率：
\newcommand{\XY}{\ensuremath{(X\comma Y)}}
\newcommand{\Cov}{\ensuremath{\mathrm{Cov}}}
\newcommand{\cip}{\tikz[baseline=-0.55ex]\draw[-stealth] (0,0) -- (2mm,0) node[above]{$\;\;P$}--+ (4mm,0);\;} %依概率收敛
\newcommand{\seriesn}{\ensuremath{\dps{\Xsum_{i=1}^n}}} %1开始到n的连续求和
\begin{document}
%\kaishu
\begin{center}
\Large{Miscellaneous Genomics Notes}
\end{center}
\begin{itemize}
\item Post-imputation information measure\footnote{\url{http://www.nature.com/articles/nrg2796}.}:
\begin{itemize}
\item Let $G_{ij}\in \{0,1,2\}$ denote the genotype of the $i$th individual at the $j$th SNP in a study cohort of $N$ samples. Let $p_{ijk} = P(G_{ij}=k|H,G)$ be the probability (obtained) from imputation that the genotype at the $j$th SNP of the $i$th individual is $k$. Define the \textcolor{magenta}{expected allele dosage} for the genotype at the $j$th SNP of the $i$th individual be
$$
e_{ij} = p_{ij1} + 2p_{ij2}
$$
Note that this equation may define $2e_{ij}$ elsewhere. Let $f_{ij} = p_{ij1} + 4p_{ij2}$, $\theta_j$ denote the unknown population allele frequency of the $j$th SNP with estimate
$$
\hat{\theta} = \dfrac{1}{2N}\Xsum_{i=1}^Ne_{ij}
$$
and $X=\Xsum_{i=1}^NG_{ij}$.
\begin{itemize}
	\item The \textcolor{magenta}{MACH $\hat{r}^2$} is the ratio of the empirically observed variance of the allele dosage to the expected binomial variance at Hardy-Weinberg equilibrium. At the $j$th SNP this is defined as 
	$$
		\hat{r}_j\f = \begin{cases}
			\dfrac{\dfrac{1}{N}\Xsum_{i=1}^N e_{ij}\f - \dfrac{1}{N\f}\left(\Xsum_{i=1}^Ne_{ij}\right)\f}{2\hat{\theta}(1-\hat{\theta})} \et \hat{\theta}\in (0,1)\\
			1 \et \hat{\theta} \in \{0,1\}
		\end{cases}	
	$$
	\item The \textcolor{magenta}{BEAGLE allelic $R\f$} is derived by approximating the $R\f$ between the best guess genotype (the most likely imputed genotype in the $i$th individual at the $j$th SNP, denoted by $z_{ij}$) and the allele dosage as an approximation of the true genotype in the case where the genotype is unknown. At the $j$th SNP this is defined as 
	$$
		R_j\f = \dfrac{\left[\Xsum_iz_{ij}e_{ij}-\dfrac{1}{N}\left(\Xsum_iz_{ij}\Xsum_ie_{ij}\right)\right]\f}{\left[\Xsum_if_{ij}-\dfrac{1}{N}\left(\Xsum_ie_{ij}\right)\f\right]\left[\Xsum_iz_{ij}\f-\dfrac{1}{N}\left(\Xsum_iz_{ij}\right)\f\right]}
	$$
	\item The \textcolor{magenta}{IMPUTE info measure} is based on measuring the relative statistical information about the population allele frequency, $\theta_j$, given by
	$$
		I_A = \begin{cases}
			1 - \dfrac{\Xsum_{i=1}^N(f_{ij} - e_{ij}\f)}{2N(\hat{\theta}(1-\hat{\theta}))} \et \hat{\theta}\in(0,1) \\ 
			1 \et \hat{\theta}\in\{0,1\}
		\end{cases}	
	$$
\end{itemize}
\item The \textcolor{magenta}{SNPTEST INFO measure}\footnote{\url{https://www.chg.ox.ac.uk/\~gav/snptest/\#info\_measures}.} is similar to the IMPUTE info measure when assuming an additive model (but not dominant model). It reflects the information in imputed genotypes relative to the information if only the allele frequency were known, defined as:
$$
\mathrm{INFO} = 1 - \dfrac{1}{N}\Xsum_{i=1}^N\dfrac{\sqrt{\hat{\theta}(1-\hat{\theta})}}{\sqrt{\theta(1-\theta)}}
$$
where the numerator $\hat{\theta}$ is the imputed allele frequency and the denominator employs the \concept{estimated allele frequency} of a given SNP across individuals (assuming HWE):
$$
\theta = \dfrac{\Xsum_i \mathrm{DS_i}}{2\Xsum_{i,g}P(g_i = g)} \qquad g\in \{0,1\}
$$
Note that INFO score equals 1 exhibits perfect imputation, and it could drop below 0.
\item The MACH, BEAGLE and IMPUTE measures seem to be highly correlated with BEAGLE $R\f$ systemically reporting lower values and undefined at $3\%$ of the SNPs and MACH $r\f$ often exceeds 1. 
\end{itemize}
\end{itemize}
\newpage
\begin{center}
\Large{Algorithms and Technicals}
\end{center}
\begin{itemize}
\item The \concept{Metropolis-Hastings Algorithm}:
\begin{itemize}
	\item Suppose we want to sample a target distribution where we don't know its normalising constant, which we denote as $p(\theta)$, but we have a known distribution $g(\theta)$ such that it satisfies $p(\theta)\propto g(\theta)$. The Metropolis-Hastings algorithm is as follows:
\begin{enumerate}
	\item Select initial value $\theta_0$.
	\item For $i=1,\cdots,m$, repeat:
	\begin{enumerate}
		\item Draw candidate $\theta^*\sim q(\theta^*\mid\theta_{i-1})$.
		\item Calculate $\alpha$ with
		$$
			\alpha = \dfrac{g(\theta^*)/q(\theta^*\mid\theta_{i-1})}{g(\theta_{i-1})/q(\theta_{i-1}\mid\theta^*)} = \dfrac{g(\theta^*)q(\theta_{i-1}\mid \theta^*)}{g(\theta_{i-1})q(\theta^*\mid\theta_{i-1})}
		$$
		\item Determine whether to retain the sample $\theta^*$ based on $\alpha$:
		\begin{itemize}
			\item If \emph{$\alpha\geq 1$}, \highlight{accept} $\theta^*$ and set $\theta_i\leftarrow\theta^*$;
			\item If \emph{$0<\alpha<1$}:
			\begin{itemize}
				\item \highlight{Accept} $\theta^*$ and set $\theta_i\leftarrow\theta^*$ with probability $\alpha$;
				\item \highlight{Reject} $\theta^*$ and set $\theta_i\leftarrow\theta_{i-1}$ with probability $1-\alpha$.
			\end{itemize}
		\end{itemize}
\end{enumerate}		
\end{enumerate}
	\item This algorithm is a valid Markov chain. One can pick $q$ such that:
	\begin{itemize}
		\item $q$ does not depend on the previous draw $\theta_{i-1}$, in this case we need to have $q$ is similar to $p$.
		\item $q$ depends on the previous draw, where we have a \concept{random walk Metropolis-Hastings}.
	\end{itemize}
	\item If we $q$ is normal, we can increase its standard deviation for decreasing acceptance rate. Targeted acceptance rate can be 23\%$-50\%$.
\end{itemize}
\item \concept{Gibbs sampling} is to sample from an unknown distribution if multiple parameters are unknown. When we sample one of the parameters, simply treat the other as a known constant (due to the chain rule of conditional probability).
\begin{itemize}
	\item Let's assume the unknown distribution is $p(\theta,\varphi\mid y)$ but we have $g(\theta,\varphi)$ that satisfies $p(\theta,\varphi\mid y)\propto g(\theta,\varphi)$. The Gibbs sampler is as follows:
\begin{enumerate}
	\item Select initial value $\theta_0$ and $\varphi_0$.
	\item For $i=1,\cdots,m$, repeat the following as one Gibbs cycle:
	\begin{enumerate}
		\item Using $\varphi_{i-1}$ to draw $\theta_i\sim p(\theta\mid\varphi_{i-1}, y)$.
		\item Using $\theta_{i}$ to draw $\varphi_i\sim p(\varphi\mid\theta_{i}, y)$.
		\item Update $(\theta_i,\varphi_i)$ according to the Metropolis-Hastings algorithm.
	\end{enumerate}		
\end{enumerate}
\end{itemize}
\item Autocorrelation:
\begin{itemize}
	\item Autocorrelation is an important structure to inspect in order to determine the validity of a MCMC simulation. If autocorrelation is high for large number of lags (one can inspect the autocorrelation plot), it probably indicates that the simulation hasn't converged to a stationary distribution, and we need to increase the number of samples drawn from the chain or modify model hyperparameters.
	\item Autocorrelation is also important in calculating the effective sample size of our MCMC. The \concept{effective sample size} is how many independent samples from the stationary distribution you would have to draw to have equivalent information in our MCMC. It is essentially the sample size we choose for our Monte Carlo estimation.
	\item Broaderly speaking, an effective sample size is often concerned in two scenarios, that is, when our data is autocorrelated or weighted. An intuitive example would be if our $X_1=\cdots=X_n$ and thus perfectly autocorrelated, we basically just have one sample; or if our samples are weighted such that $w_1=1$ and $w_2=\cdots=w_n=0$, the effective sample size is 1 as well. Mathematically, it is defined as the number of i.i.d. samples required to achieve the same level of variance.
	\item If one only cares the mean of the posterior, an effective sample size of the scale 100 to 1000 is good enough; if one seeks to create a confidence interval, then several thousands of effective samples are required.
\end{itemize}
\item \concept{Hidden Markov Model}:
\begin{itemize}
	\item Let us denote the observation sequence up to time $T$ as $O=\{O_1,O_2,\cdots,O_T\}$. An HMM consists of 5 components $N,M,A,B,$ and $\pi$:
	\begin{itemize}
		\item $N$ is the number of all possible "hidden" states at any time $t$.
		\item $M$ is the number of all observable states emitted from the hidden states at any time $t$.
		\item $A$ is the transition matrix for the hidden states.
		\item $B$ is the emission matrix for observing the observables from the hidden states, varied according to states.
		\item $\pi$ is the initial probability distribution of the hidden states at the starting point.
	\end{itemize}
	\item Three key HMM problems are posed here:
	\begin{enumerate}
		\item What is the probability that a model generated a sequence of observations $O = \{O_1,O_2,\cdots,O_T\}$ given the input parameters $\lambda = (A,B,\pi)$? Namely we want to calculate $P(O\mid\lambda)$.
		\item[$\Rightarrow$] A naive enumerating way of calculating the probability could be
		\begin{align*}
			P(O\mid\lambda) \et = \Xsum_{Q}P(O\mid Q,\lambda)P(Q\mid\lambda)\\
			\et \sim \mathcal{O}(TN^T)
		\end{align*}
		But this is computationally prohibitive. Instead, we could use the \concept{forward function $\alpha_t(i)$} where
		$$
		\alpha_t(i) = P(O_1,\cdots,O_t,q_t=S_i\mid\lambda)		
		$$
		With dynamic programming, we could solve this inductively:
		\begin{align*}
			\alpha_1(i) \et = \pi_i b_i (O_1)\\
			\alpha_{t+1}(j) \et = \left[\Xsum_{i=1}^N\alpha_t(i)a_{ij}\right]b_j(O_{t+1})\\
			P(O\mid\lambda) \et = \Xsum_{i=1}^N\alpha_T(i)\\
			\et \sim \mathcal{O}(N\f T)
		\end{align*}
		We also introduce the \concept{backward function $\beta_t(i)$} where
		$$
					\beta_t(i) = P(O_{t+1},\cdots,O_T\mid q_t=S_i,\lambda)		
		$$
		with the following induction:
		\begin{align*}
			\beta_T(i) \et = 1\\
			\beta_t(i) \et = \Xsum_{j=1}^N a_{ij}b_j(O_{t+1})\beta_{t+1}(j)
		\end{align*}
		\item What sequence $Q = \{q_1,q_2,\cdots,q_T\}$ of states best explains a sequence of observations $O = \{O_1,O_2,\cdots,O_T\}$?
		\item[$\Rightarrow$] Denote $\gamma_t(i)$ as the probability of being in state $S_i$ at time $t$, we can easily calculate this as
		\begin{align*}
			\gamma_t(i) \et = P(q_t = S_i\mid O,\lambda)	\\
			\et = \dfrac{\alpha_t(i)\beta_t(i)}{P(O\mid\lambda)} = \dfrac{\alpha_t(i)\beta_t(i)}{\Xsum_{j=1}^N\alpha_t(j)\beta_t(j)}
		\end{align*}
		An intuitive thought about $\gamma$ would be dividing the probability of getting the full sequence of observation up to time $T$ given the current state over the total probability of observing that sequence. It is easy to observe that $\Xsum_{i=1}^N\gamma_t(i) = 1$.\\
		Now, it becomes natural to consider at each $t\leq T$, what is the maximum likely state the observable is in. However, considering this sequential maximum does not necessarily make sense, at they may not form a valid path (path with non-zero probability). Hence, the better way of considering this is to find \emph{the most likely state sequence}, namely $P(Q\mid O,\lambda)$.\\
		The resulting algorithm that solves this problem is called the \concept{Viterbi algorithm}. Denote
		$$
		\delta_t(i) = \max_{q_1,\cdots,q_{t-1}}P(\{q_1,\cdots,q_{t-1},q_t=i\},\{O_1,\cdots,O_t\}\mid\lambda)
		$$
		as the path with the highest probability that accounts for the first $t$ observations and ends at state $S_i$. We use $\psi_t(i)$ to track the state at $t$ that maximises $\delta_t(i)$. The Viterbi algorithm can then be formulated as 
		\begin{alignat*}{3}
			\delta_1(i) &= \pi_i b_i (O_1) &\psi_1(i) & = 0 \\
			\delta_t(j) & = \max_{1\leq i\leq N}[\delta_{t-1}(i)a_{ij}]\cdot b_j(O_t)  \qquad & \psi_t(j) & = \argmax_{1\leq i\leq N}[\delta_{t-1}(i)a_{ij}]\\
			P^* \et = \max_{1\leq i\leq N}[\delta_T(i)] \et q_T^* \et = \argmax_{1\leq i\leq N}[\delta_T(i)]
		\end{alignat*}
		And we have $q_t^*=\psi_{t+1}(q^*_{t+1})$ where here the $*$ is to denote the optimal variables.
		\item Given a set of observation sequences $O = \{O_1,O_2,\cdots,O_T\}$, how do we learn the model parameters $\lambda = (A,B,\pi)$ that would generate them?
		\item[$\Rightarrow$]	This can be done with the \concept{Baum-Welch Algorithm}. It is an \concept{expectation-maximisation (EM)} method (a.k.a., gradient "descent"), iterative, and converges to a \emph{local} optimum. \\
		Denote $\xi_t(i,j)$ as
		\begin{align*}
		\xi_t(i,j) \et = P(q_t = S_i, q_{t+1} = S_j\mid O,\lambda)\\
		\et = \dfrac{\alpha_t(i)a_{ij}b_j(O_{t+1})\beta_{t+1}(j)}{P(O\mid\lambda)}\\
		\et = \dfrac{\alpha_t(i)a_{ij}b_j(O_{t+1})\beta_{t+1}(j)}{\Xsum_{i=1}^N\Xsum_{j=1}^N\alpha_t(i)a_{ij}b_j(O_{t+1})\beta_{t+1}(j)}
		\end{align*}
		It is notable that $\gamma_t(i) = \Xsum_{j=1}^N\xi_t(i,j)$. Now, to estimate the parameter, we could use
		\begin{align*}
			\hat{\pi} \et = \gamma_1(i)\\
			\hat{a}_{ij} \et = \dfrac{\Xsum_{t=1}^{T-1}\xi_t(i,j)}{\Xsum_{t=1}^{T-1}\gamma_t(i)}\\
			\hat{b}_j(k) \et = \dfrac{\Xsum^T_{t=1, \mathrm{\; s.t.\;}O_t=v_k}\gamma_t(i)}{\Xsum_{t=1}^T\gamma_t(i)}
		\end{align*}
		We are then able to iteratively update our model parameters $\lambda$ with the previous observations, and update the observations with the new parameters, until we reach a local maximum or minimum (which is the essence of EM).
	\end{enumerate}
\end{itemize}
\end{itemize}
\end{document}
